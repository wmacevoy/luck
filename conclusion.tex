\chapter{Conclusions}

So what is luck?  It is a mathematical definition with a useful analogy.  That's important, because it makes it easier to understand ``luck'' over ``$p$-value'', or (worse) ``generalized $p$-value''.\marginnote{Luck and generalized $p$-value are related by $L=1-p$ for probability spaces where $\max |\omega|=0$.}  

The luck perspective on normal distributions provides surprising insights on the way observations accumulate and how to accommodate multiple observations into an overall statistic\marginnote{We invoke an unproven generalization of the central limit theorem that evidently works.}.  There are also some handy algebraic tools to work out luck in the large.

Most generally, it is common to have only observations and perhaps a model for a statistical process.  The numerical section describes how to estimate luck for such systems, and what kind of error tolerances to expect when using them.  This important because so much of probability and statistics is non-parametric, including Bayesian statistics.

The chapter on randomness combines these ideas into a practical luck-based litmus test for randomness and demonstrates how it can be very efficient at identifying a misbehaved random process.  It also shows how luck can be useful for summarizing a group of statistical tests.  It also nicely illustrates a statistical computational proof-of-failure.

The particular tools really come from a perspective; luck as a useful point of view.  It is more unifying and intuitive than a $p$-value.  It has best-in-class properties compared to other $p$-value-like statistics.  

Go out and try your luck today!

